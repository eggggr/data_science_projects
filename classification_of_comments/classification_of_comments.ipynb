{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Цели\" data-toc-modified-id=\"Цели-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Цели</a></span></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Создание-и-обучение-модели\" data-toc-modified-id=\"Создание-и-обучение-модели-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Создание и обучение модели</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span><ul class=\"toc-item\"><li><span><a href=\"#Комментраий-по-проекту\" data-toc-modified-id=\"Комментраий-по-проекту-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Комментраий по проекту</a></span></li></ul></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с использованием BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цели\n",
    "\n",
    "Научить модель определять позитивный ли комментарий или нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачиваем и импортируем все требуемые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn -q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.56.0 requires numpy<1.23,>=1.18, but you have numpy 1.26.4 which is incompatible.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scipy -q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas -q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade bottleneck -q --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymystem3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (1.10.0)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.17.1%2Bcu121-cp39-cp39-linux_x86_64.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.1%2Bcu121-cp39-cp39-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision) (8.4.0)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.1%2Bcu121-cp39-cp39-linux_x86_64.whl (757.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 757.3 MB 5.5 kB/s eta 0:00:0115��█████████████▌              | 414.0 MB 19.4 MB/s eta 0:00:18██████████████▉           | 494.3 MB 15.7 MB/s eta 0:00:17     |█████████████████████████▌      | 604.5 MB 60.7 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torchvision) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12==2.19.3\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 166.0 MB 36 kB/s  eta 0:00:011\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 121.6 MB 30 kB/s s eta 0:00:01     |███████████████████████████████▌| 119.5 MB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 61.8 MB/s eta 0:00:01                    | 563 kB 61.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 9.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 196.0 MB 21 kB/s  eta 0:00:012\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch) (3.0.1)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 76.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 71.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting triton==2.2.0\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 167.9 MB 32 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 731.7 MB 4.0 kB/s eta 0:00:017938��████████▎                   | 281.3 MB 4.1 MB/s eta 0:01:51��████████▌                   | 285.1 MB 4.1 MB/s eta 0:01:50��████████▊                   | 290.0 MB 4.1 MB/s eta 0:01:49��████████▉                   | 294.7 MB 4.1 MB/s eta 0:01:48�███▎                | 348.8 MB 9.5 MB/s eta 0:00:41�████████▌                | 353.7 MB 9.5 MB/s eta 0:00:40��█████████████▌              | 400.6 MB 11.5 MB/s eta 0:00:29     |█████████████████▉              | 408.0 MB 11.5 MB/s eta 0:00:29██████████████████              | 412.4 MB 11.5 MB/s eta 0:00:28     |██████████████████▌             | 422.0 MB 11.5 MB/s eta 0:00:27��██████████▊             | 426.8 MB 11.5 MB/s eta 0:00:27   | 442.8 MB 3.3 MB/s eta 0:01:27MB 3.3 MB/s eta 0:01:24��███████████████████            | 457.4 MB 3.3 MB/s eta 0:01:22██████████▎           | 463.1 MB 3.3 MB/s eta 0:01:2101:16�█████████           | 482.4 MB 3.3 MB/s eta 0:01:15��████████████████████▉          | 498.1 MB 3.6 MB/s eta 0:01:06��█████████████████████          | 502.5 MB 3.6 MB/s eta 0:01:05MB 3.6 MB/s eta 0:01:03     |██████████████████████▌         | 515.4 MB 3.6 MB/s eta 0:01:01█████▍        | 534.1 MB 3.2 MB/s eta 0:01:02��████████████████▏       | 552.5 MB 3.2 MB/s eta 0:00:56��█████████████████       | 572.1 MB 3.2 MB/s eta 0:00:50 | 616.2 MB 8.0 MB/s eta 0:00:15█████████    | 641.8 MB 4.0 MB/s eta 0:00:23��███████████████████▋   | 653.9 MB 4.0 MB/s eta 0:00:20|████████████████████████████▊   | 658.0 MB 4.0 MB/s eta 0:00:19    |██████████████████████████████  | 685.2 MB 4.1 MB/s eta 0:00:120 MB 4.1 MB/s eta 0:00:11███████▏| 713.6 MB 4.1 MB/s eta 0:00:052\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 62.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 67.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.6 MB 1.9 kB/s eta 0:00:0133                 | 14.2 MB 65.6 MB/s eta 0:00:07 | 53.5 MB 90.2 MB/s eta 0:00:04    | 59.1 MB 90.2 MB/s eta 0:00:04███▏                         | 78.6 MB 90.2 MB/s eta 0:00:04a 0:00:04                | 98.5 MB 90.2 MB/s eta 0:00:04:03    |█████████▏                      | 118.3 MB 129.9 MB/s eta 0:00:03��███████▌                    | 146.9 MB 129.9 MB/s eta 0:00:03██▏                   | 155.4 MB 79.9 MB/s eta 0:00:04 |█████████████▎                  | 170.6 MB 79.9 MB/s eta 0:00:04�█▋                 | 187.7 MB 79.9 MB/s eta 0:00:03/s eta 0:00:03    |███████████████▊                | 202.0 MB 7.5 MB/s eta 0:00:28  | 210.7 MB 7.5 MB/s eta 0:00:27��███████▏              | 220.3 MB 7.5 MB/s eta 0:00:26[K     |██████████████████▎             | 234.2 MB 7.5 MB/s eta 0:00:2423   | 253.7 MB 3.3 MB/s eta 0:00:48�█████████           | 270.4 MB 3.3 MB/s eta 0:00:43��         | 285.6 MB 3.3 MB/s eta 0:00:39█████▍        | 300.7 MB 5.6 MB/s eta 0:00:20█████▊        | 303.8 MB 5.6 MB/s eta 0:00:20██████        | 307.7 MB 5.6 MB/s eta 0:00:19��████████████████▋       | 316.3 MB 5.6 MB/s eta 0:00:17 | 343.0 MB 7.6 MB/s eta 0:00:09��███████████████████▏   | 360.9 MB 7.6 MB/s eta 0:00:07��████████████████████   | 373.0 MB 7.6 MB/s eta 0:00:05    |██████████████████████████████  | 385.9 MB 4.8 MB/s eta 0:00:06     |███████████████████████████████ | 399.0 MB 4.8 MB/s eta 0:00:03███████▍| 402.9 MB 4.8 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch) (3.8.0)\n",
      "Collecting networkx\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 89.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[K     |████████████████████▊           | 80.3 MB 9.8 MB/s eta 0:00:052 |████▎                           | 16.7 MB 57.7 MB/s eta 0:00:022          | 56.1 MB 9.8 MB/s eta 0:00:07�██████████▊                | 61.0 MB 9.8 MB/s eta 0:00:07��█▍              | 67.5 MB 9.8 MB/s eta 0:00:06\u001b[K     |████████████████████████████████| 124.2 MB 14 kB/s  eta 0:00:01███████████████          | 85.0 MB 9.8 MB/s eta 0:00:04�████████████▏      | 97.4 MB 2.6 MB/s eta 0:00:11��███████████████████▍   | 110.3 MB 2.6 MB/s eta 0:00:06��████████████████▏| 120.9 MB 2.6 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 56.5 MB 3.0 MB/s eta 0:00:011         | 10.3 MB 62.1 MB/s eta 0:00:01��████████▍                   | 21.9 MB 62.1 MB/s eta 0:00:01  | 29.5 MB 62.1 MB/s eta 0:00:01�█████████           | 37.2 MB 62.1 MB/s eta 0:00:01��███████████████   | 51.1 MB 3.0 MB/s eta 0:00:02 0:00:01██████| 56.4 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.8 MB 85.0 MB/s eta 0:00:01B/s eta 0:00:01[K     |██████████████████▉             | 11.6 MB 85.0 MB/s eta 0:00:01 MB 85.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 87.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cublas-cu12, mpmath, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusolver-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, networkx, fsspec, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.3.0\n",
      "    Uninstalling typing-extensions-4.3.0:\n",
      "      Successfully uninstalled typing-extensions-4.3.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0\n",
      "    Uninstalling torch-1.10.0:\n",
      "      Successfully uninstalled torch-1.10.0\n",
      "Successfully installed fsspec-2023.4.0 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.2.1+cu121 torchaudio-2.2.1+cu121 torchvision-0.17.1+cu121 triton-2.2.0 typing-extensions-4.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, \\\n",
    "                                    cross_val_score, TimeSeriesSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, \\\n",
    "                                  MinMaxScaler, RobustScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.metrics import roc_auc_score, f1_score, fbeta_score, make_scorer, mean_squared_error, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.base import clone\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "\n",
    "# from pymystem3 import Mystem\n",
    "import re \n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW\n",
    "\n",
    "from tqdm import notebook \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем базу данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    143106\n",
       "1     16186\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавляемся от символов, отдельных букв, слов с числами, а также переводит текст в нижний регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    This function removes punctuation, words containing numbers\n",
    "    as well as making the whole text lower-case\n",
    "    '''\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.lower()\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text= text.split()\n",
    "    for word in text:\n",
    "        if len(word) <=1:\n",
    "            text.remove(word)\n",
    "    text = ' '.join([str(elem) for elem in text])    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more cant make any real suggestions on improve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  daww he matches this background colour im seem...      0\n",
       "2  hey man im really not trying to edit war its j...      0\n",
       "3  more cant make any real suggestions on improve...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем строки с пустым тестом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 159252 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159252 non-null  object\n",
      " 1   toxic   159252 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "159252 количество строк. Оно не делится ни на какое удобное число, поэтому уберем 52 строки и сделаем батчи размером 100. 52 значения это несравнимо мало в сравнении с 159 тысячами, так что их можно спокойно убрать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159200 entries, 0 to 159199\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159200 non-null  object\n",
      " 1   toxic   159200 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "drop_indices = np.random.choice(df.index, 52, replace=False)\n",
    "df = df.drop(drop_indices).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для леммматизации. Она нам вроде не пригодится, но пока лучше просто оставим в закомментированном виде.\n",
    "\n",
    "\n",
    "```m = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    res = []\n",
    "    word_tokens = word_tokenize(text)\n",
    "    for i in word_tokens:\n",
    "        res.append(m.lemmatize(i, pos=\"v\"))\n",
    "    return(' '.join(res))\n",
    "\n",
    "df['text'] = df['text'].apply(lemmatize)\n",
    "\n",
    "df.head()  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a72d55776244d2a1a45629eac17fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1863abc95dad4cda876ac45d2300ccd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299a2d94d00b4aaaa50a292cd5bfca73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/174 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81734a6c8680431090a035d5e9f093d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/811 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "\n",
    "tokenized = df['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, max_length = 100, add_special_tokens=True, truncation =True))\n",
    "    \n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159200, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313a6e62d12842a3bcae2a9790234b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d4b74681094746846bf7e03e3f509a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.3 s, sys: 4.2 s, total: 25.5 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 100 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = []\n",
    "model.to(device)   # закидываем модель на GPU\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]).to(device) # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим BERT без GPU на всякий случай.\n",
    "```\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159200, 768)\n"
     ]
    }
   ],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "features = pd.DataFrame(features)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним в отлельный файл, чтобы не генерировать в соледующий раз заново"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(r\"features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгрузим данные из файла (в последний раз просто выгружал данные из файла, а не создавал заново, поэтому блоки выше не были запущены)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деление на тренировочную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159200 entries, 0 to 159199\n",
      "Columns: 768 entries, 0 to 767\n",
      "dtypes: float32(768)\n",
      "memory usage: 466.4 MB\n"
     ]
    }
   ],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features = features.astype('float16') # матрица не влезла в оперативную память компьютера, поэтому пришлось уменьгшить точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, df['toxic'], test_size=0.1, random_state=RANDOM_STATE)\n",
    "X_num_col = list(X_train.select_dtypes(['int64', 'float64']).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем пайплайн для различных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель и её параметры:\n",
      "\n",
      " Pipeline(steps=[('models',\n",
      "                 DecisionTreeClassifier(max_depth=8, max_features=8,\n",
      "                                        min_samples_leaf=8, min_samples_split=5,\n",
      "                                        random_state=42))])\n",
      "Метрика лучшей модели на тренировочной выборке: 0.8872321372809668\n"
     ]
    }
   ],
   "source": [
    "pipe_final= Pipeline(\n",
    "    [\n",
    "        ('models', DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_tree = [\n",
    "    # словарь для модели DecisionTreeClassifier()\n",
    "    {\n",
    "        'models': [DecisionTreeClassifier(random_state=RANDOM_STATE)],\n",
    "        'models__max_depth': range(2, 10),\n",
    "        'models__max_features': range(2, 10),\n",
    "        'models__min_samples_leaf': range(2, 10),\n",
    "        'models__min_samples_split': range(2, 10)\n",
    "    }\n",
    "]\n",
    "\n",
    "randomized_search_tree = RandomizedSearchCV(\n",
    "    pipe_final, \n",
    "    param_grid_tree, \n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    n_iter=10,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "randomized_search_tree.fit(X_train, y_train)\n",
    "\n",
    "print('Лучшая модель и её параметры:\\n\\n', randomized_search_tree.best_estimator_)\n",
    "print ('Метрика лучшей модели на тренировочной выборке:', randomized_search_tree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель и её параметры:\n",
      "\n",
      " Pipeline(steps=[('models', KNeighborsClassifier(n_neighbors=3))])\n",
      "Метрика лучшей модели на тренировочной выборке: 0.8840933490779719\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe_kneighbor = Pipeline(\n",
    "    [\n",
    "        ('models', DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_kneighbor = [\n",
    "    {\n",
    "        'models': [KNeighborsClassifier()],\n",
    "        'models__n_neighbors': range(2, 5) \n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "randomized_search_kneighbor = GridSearchCV(\n",
    "    pipe_kneighbor, \n",
    "    param_kneighbor, \n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "randomized_search_kneighbor.fit(X_train, y_train)\n",
    "\n",
    "print('Лучшая модель и её параметры:\\n\\n', randomized_search_kneighbor.best_estimator_)\n",
    "print ('Метрика лучшей модели на тренировочной выборке:', randomized_search_kneighbor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель и её параметры:\n",
      "\n",
      " Pipeline(steps=[('models',\n",
      "                 LogisticRegression(C=1, random_state=42, solver='liblinear'))])\n",
      "Метрика лучшей модели на тренировочной выборке: 0.9021982111751831\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe_lr = Pipeline(\n",
    "    [\n",
    "        ('models', DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_lr = [\n",
    "    {\n",
    "        'models': [LogisticRegression(\n",
    "            random_state=RANDOM_STATE, \n",
    "            solver='liblinear'\n",
    "        )],\n",
    "        'models__C': range(1,2) \n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "randomized_search_lr = GridSearchCV(\n",
    "    pipe_lr, \n",
    "    param_grid_lr, \n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "randomized_search_lr.fit(X_train, y_train)\n",
    "\n",
    "print('Лучшая модель и её параметры:\\n\\n', randomized_search_lr.best_estimator_)\n",
    "print ('Метрика лучшей модели на тренировочной выборке:', randomized_search_lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучше всех справилась логичтисеская регрессия. 90.2% на тренировочной выборке. Проверим ее на тестовой.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9046839174582378"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = randomized_search_lr.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличный результат, такая модель нам подойдет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Данные в хорошем состоянии их только пришлось обрабоать для обучения модели\n",
    "2. Само обучение BERT заняло около 8 минут с использованием GPU. Был использован BERT уже подготовленный к определению токсичных комментариев.\n",
    "3. Модель с лучшей метрикой f1 - это линейная регрессия с коэффициентом С = 1. Её значение - это 0.902 на тренировочной и 0.905 тестовой."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 49,
    "start_time": "2024-03-18T06:42:29.291Z"
   },
   {
    "duration": 6436,
    "start_time": "2024-03-18T06:42:39.767Z"
   },
   {
    "duration": 17024,
    "start_time": "2024-03-18T06:42:46.206Z"
   },
   {
    "duration": 2959,
    "start_time": "2024-03-18T06:43:03.232Z"
   },
   {
    "duration": 3589,
    "start_time": "2024-03-18T06:43:06.193Z"
   },
   {
    "duration": 2453,
    "start_time": "2024-03-18T06:43:09.785Z"
   },
   {
    "duration": 2341,
    "start_time": "2024-03-18T06:43:12.240Z"
   },
   {
    "duration": 6913,
    "start_time": "2024-03-18T06:43:14.583Z"
   },
   {
    "duration": 7657,
    "start_time": "2024-03-18T06:43:21.498Z"
   },
   {
    "duration": 3089,
    "start_time": "2024-03-18T06:43:29.157Z"
   },
   {
    "duration": 1829,
    "start_time": "2024-03-18T06:43:32.249Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:43:34.080Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:43:34.081Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:43:34.082Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:43:34.083Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:43:34.084Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:43:34.086Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:43:34.086Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:43:34.088Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:43:34.089Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:43:34.090Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:43:34.091Z"
   },
   {
    "duration": 1353,
    "start_time": "2024-03-18T06:44:34.658Z"
   },
   {
    "duration": 3266,
    "start_time": "2024-03-18T06:45:14.023Z"
   },
   {
    "duration": 3164,
    "start_time": "2024-03-18T06:45:17.291Z"
   },
   {
    "duration": 2689,
    "start_time": "2024-03-18T06:45:20.457Z"
   },
   {
    "duration": 2469,
    "start_time": "2024-03-18T06:45:23.149Z"
   },
   {
    "duration": 2448,
    "start_time": "2024-03-18T06:45:25.621Z"
   },
   {
    "duration": 2488,
    "start_time": "2024-03-18T06:45:28.071Z"
   },
   {
    "duration": 2719,
    "start_time": "2024-03-18T06:45:30.561Z"
   },
   {
    "duration": 2712,
    "start_time": "2024-03-18T06:45:33.282Z"
   },
   {
    "duration": 3074,
    "start_time": "2024-03-18T06:45:35.995Z"
   },
   {
    "duration": 13745,
    "start_time": "2024-03-18T06:45:39.071Z"
   },
   {
    "duration": 848,
    "start_time": "2024-03-18T06:45:52.817Z"
   },
   {
    "duration": 366,
    "start_time": "2024-03-18T06:45:53.666Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:45:54.033Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:45:54.035Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:45:54.036Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:45:54.037Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:45:54.038Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:45:54.039Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:45:54.040Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:45:54.041Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-18T06:45:54.042Z"
   },
   {
    "duration": 2547,
    "start_time": "2024-03-18T06:49:28.460Z"
   },
   {
    "duration": 29,
    "start_time": "2024-03-18T06:49:32.117Z"
   },
   {
    "duration": 6,
    "start_time": "2024-03-18T06:49:33.208Z"
   },
   {
    "duration": 5,
    "start_time": "2024-03-18T06:49:36.388Z"
   },
   {
    "duration": 11328,
    "start_time": "2024-03-18T06:49:37.604Z"
   },
   {
    "duration": 59,
    "start_time": "2024-03-18T06:49:48.935Z"
   },
   {
    "duration": 32,
    "start_time": "2024-03-18T06:49:48.996Z"
   },
   {
    "duration": 65,
    "start_time": "2024-03-18T06:49:49.030Z"
   },
   {
    "duration": 1449,
    "start_time": "2024-03-18T06:49:49.097Z"
   },
   {
    "duration": 3275,
    "start_time": "2024-03-18T07:16:37.034Z"
   },
   {
    "duration": 3077,
    "start_time": "2024-03-18T07:16:40.311Z"
   },
   {
    "duration": 2665,
    "start_time": "2024-03-18T07:16:43.389Z"
   },
   {
    "duration": 2447,
    "start_time": "2024-03-18T07:16:46.056Z"
   },
   {
    "duration": 2473,
    "start_time": "2024-03-18T07:16:48.505Z"
   },
   {
    "duration": 2428,
    "start_time": "2024-03-18T07:16:50.980Z"
   },
   {
    "duration": 2697,
    "start_time": "2024-03-18T07:16:53.410Z"
   },
   {
    "duration": 2610,
    "start_time": "2024-03-18T07:16:56.110Z"
   },
   {
    "duration": 3079,
    "start_time": "2024-03-18T07:16:58.723Z"
   },
   {
    "duration": 1365,
    "start_time": "2024-03-18T07:17:01.804Z"
   },
   {
    "duration": 6555,
    "start_time": "2024-03-22T07:17:29.457Z"
   },
   {
    "duration": 15729,
    "start_time": "2024-03-22T07:17:36.014Z"
   },
   {
    "duration": 3347,
    "start_time": "2024-03-22T07:17:51.745Z"
   },
   {
    "duration": 2495,
    "start_time": "2024-03-22T07:17:55.094Z"
   },
   {
    "duration": 5029,
    "start_time": "2024-03-22T07:17:57.591Z"
   },
   {
    "duration": 3409,
    "start_time": "2024-03-22T07:18:25.796Z"
   },
   {
    "duration": 3259,
    "start_time": "2024-03-22T07:18:36.410Z"
   },
   {
    "duration": 3337,
    "start_time": "2024-03-22T07:18:44.531Z"
   },
   {
    "duration": 2805,
    "start_time": "2024-03-22T07:18:47.871Z"
   },
   {
    "duration": 2503,
    "start_time": "2024-03-22T07:18:50.680Z"
   },
   {
    "duration": 7,
    "start_time": "2024-03-22T07:18:54.599Z"
   },
   {
    "duration": 9,
    "start_time": "2024-03-22T07:19:04.270Z"
   },
   {
    "duration": 69,
    "start_time": "2024-03-22T07:22:03.644Z"
   },
   {
    "duration": 1050,
    "start_time": "2024-03-22T07:22:10.088Z"
   },
   {
    "duration": 2826,
    "start_time": "2024-03-22T07:22:13.990Z"
   },
   {
    "duration": 66,
    "start_time": "2024-03-22T07:22:40.339Z"
   },
   {
    "duration": 16,
    "start_time": "2024-03-22T07:23:16.319Z"
   },
   {
    "duration": 36,
    "start_time": "2024-03-22T07:23:18.453Z"
   },
   {
    "duration": 375,
    "start_time": "2024-03-22T07:27:12.824Z"
   },
   {
    "duration": 7,
    "start_time": "2024-03-22T07:27:15.201Z"
   },
   {
    "duration": 89,
    "start_time": "2024-03-22T07:27:22.675Z"
   },
   {
    "duration": 4,
    "start_time": "2024-03-22T07:41:07.956Z"
   },
   {
    "duration": 4,
    "start_time": "2024-03-22T07:42:23.875Z"
   },
   {
    "duration": 73,
    "start_time": "2024-03-22T07:43:12.077Z"
   },
   {
    "duration": 7395,
    "start_time": "2024-03-22T07:43:31.260Z"
   },
   {
    "duration": 6684,
    "start_time": "2024-03-22T07:43:38.658Z"
   },
   {
    "duration": 3537,
    "start_time": "2024-03-22T07:43:45.344Z"
   },
   {
    "duration": 3087,
    "start_time": "2024-03-22T07:43:48.884Z"
   },
   {
    "duration": 2863,
    "start_time": "2024-03-22T07:43:51.975Z"
   },
   {
    "duration": 7,
    "start_time": "2024-03-22T07:43:54.842Z"
   },
   {
    "duration": 67,
    "start_time": "2024-03-22T07:43:54.851Z"
   },
   {
    "duration": 2109,
    "start_time": "2024-03-22T07:43:54.919Z"
   },
   {
    "duration": 12,
    "start_time": "2024-03-22T07:43:57.030Z"
   },
   {
    "duration": 67,
    "start_time": "2024-03-22T07:43:57.044Z"
   },
   {
    "duration": 77,
    "start_time": "2024-03-22T07:43:57.113Z"
   },
   {
    "duration": 15,
    "start_time": "2024-03-22T07:43:57.192Z"
   },
   {
    "duration": 12,
    "start_time": "2024-03-22T07:43:57.209Z"
   },
   {
    "duration": 14130,
    "start_time": "2024-03-22T07:43:57.223Z"
   },
   {
    "duration": 42,
    "start_time": "2024-03-22T07:44:11.354Z"
   },
   {
    "duration": 25,
    "start_time": "2024-03-22T07:44:11.398Z"
   },
   {
    "duration": 69,
    "start_time": "2024-03-22T07:44:11.425Z"
   },
   {
    "duration": 6,
    "start_time": "2024-03-22T07:44:39.560Z"
   },
   {
    "duration": 235090,
    "start_time": "2024-03-22T07:44:43.087Z"
   },
   {
    "duration": 77,
    "start_time": "2024-03-22T07:48:38.182Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-22T07:48:38.261Z"
   },
   {
    "duration": 4,
    "start_time": "2024-03-22T07:48:52.633Z"
   },
   {
    "duration": 72,
    "start_time": "2024-03-22T07:50:53.543Z"
   },
   {
    "duration": 7082,
    "start_time": "2024-03-23T06:52:36.386Z"
   },
   {
    "duration": 14041,
    "start_time": "2024-03-23T06:52:43.470Z"
   },
   {
    "duration": 3649,
    "start_time": "2024-03-23T06:52:57.513Z"
   },
   {
    "duration": 11177,
    "start_time": "2024-03-23T06:53:01.164Z"
   },
   {
    "duration": 3703,
    "start_time": "2024-03-23T06:53:12.344Z"
   },
   {
    "duration": 2891,
    "start_time": "2024-03-23T06:53:16.050Z"
   },
   {
    "duration": 3,
    "start_time": "2024-03-23T06:53:18.943Z"
   },
   {
    "duration": 2841,
    "start_time": "2024-03-23T06:53:18.948Z"
   },
   {
    "duration": 2,
    "start_time": "2024-03-23T06:53:21.792Z"
   },
   {
    "duration": 13947,
    "start_time": "2024-03-23T06:53:21.795Z"
   },
   {
    "duration": 6,
    "start_time": "2024-03-23T06:53:35.743Z"
   },
   {
    "duration": 12,
    "start_time": "2024-03-23T06:53:35.750Z"
   },
   {
    "duration": 1859,
    "start_time": "2024-03-23T06:53:35.764Z"
   },
   {
    "duration": 2606,
    "start_time": "2024-03-23T06:53:37.626Z"
   },
   {
    "duration": 14,
    "start_time": "2024-03-23T06:53:40.234Z"
   },
   {
    "duration": 46,
    "start_time": "2024-03-23T06:53:40.249Z"
   },
   {
    "duration": 77,
    "start_time": "2024-03-23T06:53:40.296Z"
   },
   {
    "duration": 20,
    "start_time": "2024-03-23T06:53:40.380Z"
   },
   {
    "duration": 23,
    "start_time": "2024-03-23T06:53:40.402Z"
   },
   {
    "duration": 12078,
    "start_time": "2024-03-23T06:53:40.427Z"
   },
   {
    "duration": 38,
    "start_time": "2024-03-23T06:53:52.507Z"
   },
   {
    "duration": 44,
    "start_time": "2024-03-23T06:53:52.547Z"
   },
   {
    "duration": 53,
    "start_time": "2024-03-23T06:53:52.593Z"
   },
   {
    "duration": 201504,
    "start_time": "2024-03-23T06:53:52.648Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-23T06:57:14.153Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-23T06:57:14.155Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-23T06:57:14.155Z"
   },
   {
    "duration": 210225,
    "start_time": "2024-03-23T06:57:23.227Z"
   },
   {
    "duration": 6,
    "start_time": "2024-03-23T07:00:53.454Z"
   },
   {
    "duration": 14226,
    "start_time": "2024-03-23T07:00:53.461Z"
   },
   {
    "duration": 117,
    "start_time": "2024-03-23T07:01:07.689Z"
   },
   {
    "duration": 4613,
    "start_time": "2024-03-23T08:29:21.072Z"
   },
   {
    "duration": 5,
    "start_time": "2024-03-23T08:29:27.713Z"
   },
   {
    "duration": 2532,
    "start_time": "2024-03-23T08:29:33.127Z"
   },
   {
    "duration": 6706,
    "start_time": "2024-03-23T08:29:44.493Z"
   },
   {
    "duration": 13227,
    "start_time": "2024-03-23T08:29:51.202Z"
   },
   {
    "duration": 3467,
    "start_time": "2024-03-23T08:30:04.430Z"
   },
   {
    "duration": 10369,
    "start_time": "2024-03-23T08:30:07.900Z"
   },
   {
    "duration": 3307,
    "start_time": "2024-03-23T08:30:18.272Z"
   },
   {
    "duration": 2556,
    "start_time": "2024-03-23T08:30:21.581Z"
   },
   {
    "duration": 2552,
    "start_time": "2024-03-23T08:30:24.140Z"
   },
   {
    "duration": 2495,
    "start_time": "2024-03-23T08:30:26.695Z"
   },
   {
    "duration": 315754,
    "start_time": "2024-03-23T08:30:29.193Z"
   },
   {
    "duration": 9997,
    "start_time": "2024-03-23T08:35:44.952Z"
   },
   {
    "duration": 11,
    "start_time": "2024-03-23T08:35:54.952Z"
   },
   {
    "duration": 9,
    "start_time": "2024-03-23T08:35:54.966Z"
   },
   {
    "duration": 2171,
    "start_time": "2024-03-23T08:35:54.978Z"
   },
   {
    "duration": 2512,
    "start_time": "2024-03-23T08:35:57.151Z"
   },
   {
    "duration": 61,
    "start_time": "2024-03-23T08:35:59.665Z"
   },
   {
    "duration": 70,
    "start_time": "2024-03-23T08:35:59.729Z"
   },
   {
    "duration": 106,
    "start_time": "2024-03-23T08:35:59.801Z"
   },
   {
    "duration": 10,
    "start_time": "2024-03-23T08:35:59.909Z"
   },
   {
    "duration": 8,
    "start_time": "2024-03-23T08:35:59.921Z"
   },
   {
    "duration": 12441,
    "start_time": "2024-03-23T08:35:59.933Z"
   },
   {
    "duration": 183,
    "start_time": "2024-03-23T08:36:12.376Z"
   },
   {
    "duration": 715,
    "start_time": "2024-03-23T08:36:12.561Z"
   },
   {
    "duration": 742,
    "start_time": "2024-03-23T08:36:13.277Z"
   },
   {
    "duration": 227178,
    "start_time": "2024-03-23T08:36:14.021Z"
   },
   {
    "duration": 4,
    "start_time": "2024-03-23T08:40:01.201Z"
   },
   {
    "duration": 10482,
    "start_time": "2024-03-23T08:40:01.207Z"
   },
   {
    "duration": 67292,
    "start_time": "2024-03-23T08:40:11.691Z"
   },
   {
    "duration": 58,
    "start_time": "2024-03-23T08:42:45.126Z"
   },
   {
    "duration": 6763,
    "start_time": "2024-03-23T09:52:00.725Z"
   },
   {
    "duration": 12999,
    "start_time": "2024-03-23T09:52:07.490Z"
   },
   {
    "duration": 3710,
    "start_time": "2024-03-23T09:52:20.491Z"
   },
   {
    "duration": 10404,
    "start_time": "2024-03-23T09:52:24.203Z"
   },
   {
    "duration": 3245,
    "start_time": "2024-03-23T09:52:34.610Z"
   },
   {
    "duration": 2787,
    "start_time": "2024-03-23T09:52:37.857Z"
   },
   {
    "duration": 2722,
    "start_time": "2024-03-23T09:52:40.646Z"
   },
   {
    "duration": 2652,
    "start_time": "2024-03-23T09:52:43.370Z"
   },
   {
    "duration": 286181,
    "start_time": "2024-03-23T09:52:46.024Z"
   },
   {
    "duration": 17697,
    "start_time": "2024-03-23T09:57:32.207Z"
   },
   {
    "duration": 8,
    "start_time": "2024-03-23T09:57:49.907Z"
   },
   {
    "duration": 6,
    "start_time": "2024-03-23T09:57:49.917Z"
   },
   {
    "duration": 1007,
    "start_time": "2024-03-23T09:57:49.924Z"
   },
   {
    "duration": 2741,
    "start_time": "2024-03-23T09:57:50.934Z"
   },
   {
    "duration": 551,
    "start_time": "2024-03-23T09:57:53.677Z"
   },
   {
    "duration": 726,
    "start_time": "2024-03-23T09:57:54.229Z"
   },
   {
    "duration": 285,
    "start_time": "2024-03-23T09:57:54.956Z"
   },
   {
    "duration": 1677,
    "start_time": "2024-03-23T09:57:55.243Z"
   },
   {
    "duration": 653,
    "start_time": "2024-03-23T09:57:56.922Z"
   },
   {
    "duration": 14170,
    "start_time": "2024-03-23T09:57:57.576Z"
   },
   {
    "duration": 42,
    "start_time": "2024-03-23T09:58:11.747Z"
   },
   {
    "duration": 27,
    "start_time": "2024-03-23T09:58:11.791Z"
   },
   {
    "duration": 68,
    "start_time": "2024-03-23T09:58:11.820Z"
   },
   {
    "duration": 212062,
    "start_time": "2024-03-23T09:58:11.890Z"
   },
   {
    "duration": 7,
    "start_time": "2024-03-23T10:01:43.953Z"
   },
   {
    "duration": 9301,
    "start_time": "2024-03-23T10:01:43.962Z"
   },
   {
    "duration": 25735,
    "start_time": "2024-03-23T10:01:53.265Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
